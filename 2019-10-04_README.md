
<br/>
김도진 - <br/>
  My role for this project was to create an object detection model that can detect drone, car, and person.
  At the beginning, I wrote a python code that reads a video or webcam and detects objects that are defined in COCO dataset.
  --> Did you test with a video? Where did you get the video from? Who recorded video? What objects were there?
  --> What do you menas that "objects that are defined in COCO dataset"? The objects in the COCO classese?
  --> Then What are in the COCO classes? What objects did you detect from the video exactly?
  I wrote 3 codes, which are codes that detect objects with pre-trained yolov and yolov3-tiny models using opencv DNN, Pytorch, and Tensorflow.
  --> What are the combination of the 3 codes? tiny YOLO and tensorflow, tiny YOLO and Pytorch?
  --> What are the results of that in terms of training loss, training accuracy, valivation loss, and validation accuracy?
  --> What are the accuracy of evaluation result? How deep is the net? What are the parameters of tiny YOLO and YOLOv3?
  --> Why do you pick the two ML model in detail (any reference)?
  Compared performance of each codes and concluded that if not using the GPU while inferring, using opencv DNN is the fastest.
  --> Provide graph data of the result. Background must be white, add title in each axis, font size of title be big.
  --> Leave the plotting code and input data as a txt file in a folder (make a new folder in this git).
  I ended up using yolov3 and yolov3-tiny because it is much faster than faster rcnn or mask rcnn. <br/><br/>
  --> Why that is faster then rcnns? Explain it in details. And also where the processing is time consuming (inference step or drawing step, etc)
  
  After figuring out what framework to use, I searched for image datasets to train yolov3.
  --> Framework here is maybe the ML model and tool configuration?
  I found about 2600 drone images from github and about 2600 person & car images from Pascal VOC dataset.
  --> Where did you fint the drone images? Please leave the github address here.
  I converted Pascal VOC dataset labels into YOLO format.
  --> Why and how did you do that? Can't you just use the images rightaway? Where is the code? Explain the process in detail.
  While converting to YOLO format, imprecise labels were generated so I looked all images and fixed labels.
  --> Why the imprecise labels were generated? Who generated them? How that was happened? How did you fixed the labels?
  After dataset was prepared, I used google colab to train custom classes. 
  I used google colab because training process required GPU but I did not have one.
  --> Why you have to use GPU? Why not only with CPUs? What was the learning rate and how much time required with CPUs for training?
  --> Do you think that is reason of CPU and GPU? Not memory? Why did you come up with that you need GPU?
  Google colab provided free GPUs for 12hours per session. Training dataset took about 18 hours.<br/>
  --> How much of CPUs, GPUs, and memory? How did you come up with trained model when it took 18 hrs and Google provides 12 hrs?
  
  In coming weeks, I will install ros in raspberry pi and upload custom-trained yolo weights, detection codes to the device.
  --> Why are you using raspberry pi? What's the reason that you need the device?
  I will test how well the model detects objects.
  --> How will you test? What is the test procedure for it? 
  If the accuracy is low I will figure out other ways to enhance the performance.
  --> What accuracy range is "low"? How do you determine that? How would you enhance the performance?
  Also, I will integrate camera detetion system with ros nodes. If everything is set I will help radar team for analyzing the SAR image using machine learning. I am not familiar with ros so integrating might be difficult, but I will ask other teammates who are familiar with ros to solve the problem.
  --> What is the design of the data flow and data analysis flor of the camera node and camera node related nodes?
  --> GREAT!
<br/>
Below is gif showing how drones are detected using pre-trained yolo drone weight

[Drone-detection](https://i.imgur.com/5UL6AvU.gifv)

--> Rander that as a gif or mp4 or wav or other type and upload the result in this git

Below is repository I am working on for camera detection

[drone_detection Repo](https://github.com/dojinkimm/drone_detection)

--> Sync this repository to a foler (make a folder here for you) with the same name in this repository weekly
